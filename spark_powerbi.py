import os
import pandas as pd
import time
from pyspark.sql import SparkSession
from pyspark.sql.types import *
from pyspark.sql.functions import col, count, when, sum as spark_sum, avg, round, udf, lit
from pyspark.sql.types import FloatType, DecimalType
from delta import configure_spark_with_delta_pip
from pyspark.sql.functions import format_number, regexp_replace
from pyspark.sql.functions import round, col, regexp_replace

# Path to existing Delta tables
DELTA_PATH = "/data/delta_sport_activities"
EMPLOYEE_PRIME_PATH = "/data/delta_employee_prime"

# Python environment inside Spark workers
os.environ['PYSPARK_PYTHON'] = 'python3'
os.environ['PYSPARK_DRIVER_PYTHON'] = 'python3'

# Build SparkSession with Delta
builder = SparkSession.builder \
    .appName("PowerBIExporter") \
    .config("spark.jars.packages", "io.delta:delta-spark_2.12:3.2.0") \
    .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension") \
    .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog")

spark = configure_spark_with_delta_pip(builder).getOrCreate()
spark.sparkContext.setLogLevel("WARN")

# D√©finir une UDF pour convertir les salaires
def convert_salaire(salaire_str):
    try:
        return float(salaire_str)
    except:
        return 30000.0

convert_salaire_udf = udf(convert_salaire, FloatType())

# Fonction pour exporter les donn√©es en temps r√©el
def export_realtime_data():
    export_dir = "/data/powerbi_export"
    os.makedirs(export_dir, exist_ok=True)

    moyens_ecologiques = ["Marche/running", "V√©lo/Trottinette/Autres", "Marche_running", "Velo_Trottinette_Autres"]

    while True:
        try:
            print("\n" + "="*70)
            print("LECTURE DES DONN√âES DELTA POUR EXPORT POWER BI")
            print("="*70)

            # Lire la table Delta des activit√©s sportives
            try:
                df_activities = spark.read.format("delta").load(DELTA_PATH)
                activities_count = df_activities.count()
                print(f"Nombre d'activit√©s dans Delta: {activities_count}")
            except Exception as e:
                print(f"Erreur lors de la lecture des activit√©s: {e}")
                df_activities = None

            # Lire la table Delta des primes employ√©s
            try:
                df_employee = spark.read.format("delta").load(EMPLOYEE_PRIME_PATH)

                if "prime_annuelle" not in df_employee.columns:
                    df_employee = df_employee.withColumn(
                        "salaire_brut_float",
                        convert_salaire_udf(col("salaire_brut"))
                    )
                    df_employee = df_employee.withColumn(
                        "prime_annuelle",
                        when(col("moyen_deplacement").isin(moyens_ecologiques),
                             round(col("salaire_brut_float") * 0.05, 2))
                        .otherwise(lit(0.0))
                    )

                df_primes = df_employee.select(
                    col("id_salarie").alias("ID_employee"),
                    "moyen_deplacement",
                    col("prime_annuelle").cast(DecimalType(10, 2)).alias("prime_annuelle"),
                    convert_salaire_udf(col("salaire_brut")).cast(DecimalType(10, 2)).alias("salaire_brut")
                )

                print(f"Nombre d'employ√©s dans Delta (avant d√©duplication): {df_primes.count()}")

            except Exception as e:
                print(f"Erreur lors de la lecture des primes: {e}")
                df_primes = None

            # Fonction d‚Äôexport avec pandas d√©duplication
            def export_single_file(df, filename):
                if df is not None and df.count() > 0:
                    try:
                        temp_path = f"{export_dir}/temp_{filename}"
                        df.coalesce(1).write \
                            .mode("overwrite") \
                            .option("header", "true") \
                            .option("delimiter", ";") \
                            .option("decimal", ".") \
                            .csv(temp_path)

                        import glob, shutil
                        csv_files = glob.glob(f"{temp_path}/*.csv")
                        if not csv_files:
                            print(f"‚ùå Aucun fichier g√©n√©r√© pour {filename}")
                            return False

                        final_path = f"{export_dir}/{filename}"
                        shutil.move(csv_files[0], final_path)
                        shutil.rmtree(temp_path)

                        # --- Post-traitement pandas : garder la derni√®re version ---
                        try:
                            pdf = pd.read_csv(final_path, sep=';')

                            if 'ID_employee' in pdf.columns:
                                id_col = 'ID_employee'
                            elif 'id_salarie' in pdf.columns:
                                id_col = 'id_salarie'
                            else:
                                print("‚ö†Ô∏è Pas de colonne ID trouv√©e, pas de d√©duplication.")
                                return True

                            # garder la derni√®re occurrence
                            pdf_dedup = pdf.drop_duplicates(subset=[id_col], keep='last')

                            pdf_dedup.to_csv(final_path, sep=';', index=False, float_format="%.2f")

                            print(f"‚úÖ Export (d√©dupliqu√©) r√©ussi: {final_path}")
                            print(f"üìä Lignes export√©es apr√®s d√©dup: {len(pdf_dedup)}")
                            print("Aper√ßu:")
                            print(pdf_dedup.head().to_string(index=False))

                        except Exception as e_pd:
                            print(f"‚ö†Ô∏è Erreur pandas lors du d√©dup: {e_pd}")
                            print(f"‚úÖ Export brut conserv√©: {final_path}")

                        return True

                    except Exception as e:
                        print(f"‚ùå Erreur export {filename}: {e}")
                        return False
                else:
                    print(f"‚ö†Ô∏è Aucune donn√©e √† exporter pour {filename}")
                    return False
                

            def export_single_fileWithDuplication(df, filename):
                if df is not None and df.count() > 0:
                    try:
                        temp_path = f"{export_dir}/temp_{filename}"
                        df.coalesce(1).write \
                            .mode("overwrite") \
                            .option("header", "true") \
                            .option("delimiter", ";") \
                            .option("decimal", ".") \
                            .csv(temp_path)

                        import glob, shutil
                        csv_files = glob.glob(f"{temp_path}/*.csv")
                        if not csv_files:
                            print(f"‚ùå Aucun fichier g√©n√©r√© pour {filename}")
                            return False

                        final_path = f"{export_dir}/{filename}"
                        shutil.move(csv_files[0], final_path)
                        shutil.rmtree(temp_path)

                        # --- Post-traitement pandas : garder la derni√®re version ---
                        try:
                            pdf = pd.read_csv(final_path, sep=';')

                            if 'ID_employee' in pdf.columns:
                                id_col = 'ID_employee'
                            elif 'id_salarie' in pdf.columns:
                                id_col = 'id_salarie'
                            else:
                                print("‚ö†Ô∏è Pas de colonne ID trouv√©e, pas de d√©duplication.")
                                return True

                            # garder la derni√®re occurrence
                            #pdf_dedup = pdf.drop_duplicates(subset=[id_col], keep='last')

                            pdf.to_csv(final_path, sep=';', index=False, float_format="%.2f")

                            print(f"‚úÖ Export (with d√©dupliqu√©) r√©ussi: {final_path}")
                            print(f"üìä Lignes export√©es apr√®s d√©dup: {len(pdf)}")
                            print("Aper√ßu:")
                            print(pdf.head().to_string(index=False))

                        except Exception as e_pd:
                            print(f"‚ö†Ô∏è Erreur pandas lors du d√©dup: {e_pd}")
                            print(f"‚úÖ Export brut conserv√©: {final_path}")

                        return True

                    except Exception as e:
                        print(f"‚ùå Erreur export {filename}: {e}")
                        return False
                else:
                    print(f"‚ö†Ô∏è Aucune donn√©e √† exporter pour {filename}")
                    return False



            df_primes_export = df_primes.withColumn(
                "prime_annuelle",
                regexp_replace(round(col("prime_annuelle"), 2).cast("string"), r"\.", ",")
            ).withColumn(
                "salaire_brut",
                regexp_replace(round(col("salaire_brut"), 2).cast("string"), r"\.", ",")
            )


            # Exporter les fichiers
            export_single_fileWithDuplication(df_activities, "activites_sportives.csv")
            print("\n" + "-"*50)
            export_single_file( df_primes_export, "primes_employes.csv")




            # Exporter des statistiques suppl√©mentaires
            if df_primes is not None:
                stats_primes = df_primes.groupBy("moyen_deplacement") \
                    .agg(
                        count("*").alias("Nombre_employes"),
                        round(avg("prime_annuelle"), 2).alias("Prime_moyenne"),
                        round(spark_sum("prime_annuelle"), 2).alias("Budget_total")
                    ) \
                    .orderBy(col("Budget_total").desc())
                export_single_file(stats_primes, "statistiques_primes.csv")

            print("\n" + "="*70)
            print("‚úÖ EXPORT POWER BI TERMIN√â!")
            print("="*70)

        except Exception as e:
            print(f"‚ùå Erreur lors de l'export: {e}")
            import traceback
            traceback.print_exc()

        print("\n‚è≥ Attente de 30 secondes avant le prochain export...")
        time.sleep(30)

# D√©marrer l'export en temps r√©el
export_realtime_data()

# Stop Spark
spark.stop()
