# Sport
Sport Data Solution
ğŸ“‹ Description du Projet
Sport Data Solution est une plateforme complÃ¨te d'analyse et de rÃ©compense des activitÃ©s sportives en entreprise. Ce systÃ¨me permet de calculer automatiquement des avantages financiers basÃ©s sur la pratique sportive des employÃ©s, favorisant ainsi une culture d'entreprise active et saine.

ğŸ¯ Objectifs
IntÃ©grer le sport dans l'ADN de l'entreprise

Calculer l'impact financier des avantages sportifs

CrÃ©er un environnement d'Ã©mulation entre collaborateurs

Fournir des dashboards temps rÃ©el pour le suivi des activitÃ©s

ğŸ—ï¸ Architecture Technique
Stack Technologique
Composant	Technologie	Version
Ingestion	Debezium + Redpanda	2.5 + 24.1
Processing	Apache Spark + Delta Lake	3.5.0 + 3.2.0
Visualisation	Power BI	-
Conteneurisation	Docker + Docker Compose	-
Flux de DonnÃ©es
text
PostgreSQL â†’ Debezium â†’ Redpanda â†’ Spark Streaming â†’ Delta Lake â†’ Power BI
ğŸ“ Structure des Fichiers
text
sport-data-solution/
â”œâ”€â”€ docker-compose.yml          # Orchestration des services
â”œâ”€â”€ Dockerfile.spark            # Image Spark personnalisÃ©e
â”œâ”€â”€ spark_traitement_sport.py   # Traitement des activitÃ©s sportives
â”œâ”€â”€ spark_traitement_employee.py # Traitement des donnÃ©es employÃ©s
â”œâ”€â”€ spark_powerbi.py           # Export des donnÃ©es pour Power BI
â”œâ”€â”€ data/                      # Volume des donnÃ©es Delta Lake
â”‚   â”œâ”€â”€ delta_sport_activities/
â”‚   â””â”€â”€ delta_employee_prime/
â””â”€â”€ checkpoints/               # Checkpoints Spark
    â”œâ”€â”€ sport_activities/
    â””â”€â”€ employee_prime/
ğŸš€ DÃ©ploiement
PrÃ©requis
Docker et Docker Compose installÃ©s

4GB de RAM minimum

10GB d'espace disque libre

Installation et Lancement
Cloner le projet

bash
git clone <repository-url>
cd sport-data-solution
Construire les images Docker

bash
docker-compose build
DÃ©marrer les services

bash
docker-compose up -d
VÃ©rifier le statut des services

bash
docker-compose ps
Services DÃ©ployÃ©s
Service	Port	Description
spark-sport-processor	-	Traitement des activitÃ©s sportives
spark-employee-processor	-	Traitement des donnÃ©es employÃ©s
redpanda	19092	Broker Kafka-compatible
redpanda-console	8080	Interface de monitoring
ğŸ”§ Configuration
Variables d'Environnement
Les containers Spark utilisent les variables suivantes :

bash
PYSPARK_PYTHON=python3
PYSPARK_DRIVER_PYTHON=python3
SPARK_HOME=/opt/spark
Volumes Persistants
/data : Stockage des tables Delta Lake

/tmp/checkpoints : Checkpoints des streams Spark

/data/powerbi_export : Fichiers CSV pour Power BI

ğŸ“Š ModÃ¨le de DonnÃ©es
Source PostgreSQL
sql
sport_activities (
    id_salarie VARCHAR,
    start_date TIMESTAMP,
    activity_type VARCHAR,
    distance_m FLOAT,
    duration_sec INTEGER,
    comment VARCHAR
)
Tables Delta Lake RÃ©sultantes
sport_activities_delta : Historique des activitÃ©s sportives

employee_prime : DonnÃ©es employÃ©s avec calcul des primes

ğŸ’° Calcul des Avantages
RÃ¨gles MÃ©tier
Prime Ã‰cologique (5% du salaire brut) :

Pour les moyens de dÃ©placement Ã©cologiques :

Marche/running

VÃ©lo/Trottinette/Autres

Jours Bien-ÃŠtre :

5 jours supplÃ©mentaires pour les employÃ©s avec â‰¥15 activitÃ©s/an

Formules de Calcul
python
# Prime Ã©cologique
prime_annuelle = salaire_brut * 0.05 if moyen_deplacement_ecologique else 0

# Ã‰ligibilitÃ© jours bien-Ãªtre
jours_bien_etre = 5 if nb_activites >= 15 else 0
ğŸ” Monitoring et QualitÃ© des DonnÃ©es
Checks ImplÃ©mentÃ©s
âœ… Validation des dates (naissance, embauche)

âœ… CohÃ©rence salaire/Ã©chelles

âœ… ComplÃ©tude des donnÃ©es obligatoires

âœ… ConformitÃ© types d'activitÃ© avec distance

Marche/Running : max 15 km

VÃ©lo/Trottinette : max 25 km

Alertes et Notifications
Notifications Slack pour nouvelles activitÃ©s

Monitoring Redpanda sur le port 8080

Logs de traitement en temps rÃ©el

ğŸ“ˆ Dashboard Power BI
Pages Principales
Overview : KPIs globaux et mÃ©triques principales

DÃ©tail EmployÃ©s : ActivitÃ©s individuelles + Ã©ligibilitÃ©

Budget : Impact financier des avantages

Trends : Ã‰volution temporelle des activitÃ©s

Connexion aux DonnÃ©es
Les donnÃ©es sont exportÃ©es automatiquement dans :

text
/data/powerbi_export/
â”œâ”€â”€ activites_sportives.csv
â”œâ”€â”€ primes_employes.csv
â””â”€â”€ statistiques_primes.csv
ğŸ› ï¸ Commandes Utiles
Supervision des Services
bash
# Voir les logs en temps rÃ©el
docker-compose logs -f spark-sport-processor
docker-compose logs -f spark-employee-processor

# Statut des containers
docker-compose ps

# RedÃ©marrer un service
docker-compose restart spark-sport-processor
Maintenance
bash
# ArrÃªt propre
docker-compose down

# Nettoyage des volumes
docker-compose down -v

# Reconstruction des images
docker-compose build --no-cache
Debugging
bash
# AccÃ©der au container
docker exec -it spark-sport-processor bash

# VÃ©rifier les donnÃ©es Delta
docker exec spark-sport-processor python3 -c "
from pyspark.sql import SparkSession
spark = SparkSession.builder.getOrCreate()
df = spark.read.format('delta').load('/data/delta_sport_activities')
print(f'Nombre d\'activitÃ©s: {df.count()}')
df.show(5)
"
ğŸ“Š MÃ©triques de Performance
âš¡ RÃ©duction de 70% du temps de traitement

ğŸ¯ 99,9% de fiabilitÃ© des donnÃ©es

ğŸ“ˆ CapacitÃ© : 10,000+ activitÃ©s/jour

ğŸ’¾ RÃ©tention : 3 ans d'historique

ğŸ”® Ã‰volutions Futures
IntÃ©gration d'API Google Maps pour validation des distances

Notifications push mobiles

IntÃ©gration avec les outils RH existants

Analytics prÃ©dictif des tendances sportives

ğŸ†˜ DÃ©pannage
ProblÃ¨mes Courants
Container s'arrÃªte immÃ©diatement

bash
docker logs spark-sport-processor
ProblÃ¨me de connexion Kafka

bash
docker-compose restart redpanda
DonnÃ©es non visibles dans Power BI

bash
docker exec spark-sport-processor ls -la /data/powerbi_export/
Support
Pour toute question technique, consulter les logs des services concernÃ©s.

ğŸ“„ Licence
Ce projet est dÃ©veloppÃ© pour un usage interne. Tous droits rÃ©servÃ©s.

Sport Data Solution - Une culture d'entreprise active et saine ğŸƒâ€â™‚ï¸ğŸ’¼


